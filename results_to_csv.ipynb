{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, efficientnet_b5, densenet161\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, roc_curve, RocCurveDisplay\n",
    "# sensitivity, specificity, precision, recall, f1_score, roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, hamming_loss, zero_one_loss\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "model_path = \"./AUG-New-IISc/best_model/models/best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"./data-iisc\"\n",
    "images_dir = \"train_data_dir\"\n",
    "train_csv = \"train_data.csv\"\n",
    "val_csv = \"val_data.csv\"\n",
    "test_csv = \"test_data.csv\"\n",
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            images_dir,\n",
    "            aug_fn=None,\n",
    "            preprocessing=None,\n",
    "    ):\n",
    "\n",
    "        self.ids = [img for img in os.listdir(images_dir) if img.endswith('.png')]\n",
    "\n",
    "        self.images = [os.path.join(images_dir, img) for img in self.ids]\n",
    "\n",
    "        self.aug_fn = aug_fn\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.images[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.aug_fn:\n",
    "            sample = self.aug_fn(image.shape)(image=image)\n",
    "            image = sample['image']\n",
    "\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "\n",
    "        return image, self.ids[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image, pass it through albumentations, get the predicted labels, and then show the image\n",
    "def resize_image(image_shp, target_size=512):\n",
    "    \"\"\"\n",
    "    Resize the image to the target size\n",
    "    :param image: The image to resize\n",
    "    :param target_size: The target size\n",
    "    :return: The resized image\n",
    "    \"\"\"\n",
    "    h, w, _ = image_shp\n",
    "\n",
    "    max_size = max(h, w)\n",
    "\n",
    "    transform = A.Compose([\n",
    "    A.PadIfNeeded(min_height=max_size, min_width=max_size, border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255)),\n",
    "    A.Resize(512, 512, interpolation=cv2.INTER_AREA),\n",
    "    # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    return transform\n",
    "\n",
    "# %%\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype(\"float32\")\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn=None):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "\n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function\n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _transform = [\n",
    "        # Lambda(image=preprocessing_fn),\n",
    "        A.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet161(weights='DEFAULT')\n",
    "model.classifier = torch.nn.Linear(2208, 6)\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "checkpoint = torch.load(model_path,map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_epoch_runner_confidence_output(description:str, loader, model, device=\"cuda\"):\n",
    "\n",
    "    header = [\"ImageID\", \"Class 1\",\"Class 2\",\"Class 3\",\"Class 4\",\"Class 5\",\"Class 6\"]\n",
    "    epoch_df = pd.DataFrame(columns=header)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(loader, desc=description.title()) as iterator:\n",
    "            for images, img_ids in iterator:\n",
    "\n",
    "                images = images.to(device)\n",
    "                outputs = model.forward(images)\n",
    "                sigmoid_outputs = torch.sigmoid(outputs)\n",
    "\n",
    "                for i in range(len(sigmoid_outputs)):\n",
    "                    # get the image id\n",
    "                    # get the sigmoid outputs\n",
    "\n",
    "                    img_id = img_ids[i]\n",
    "                    sigmoid_output = np.round(sigmoid_outputs[i].cpu().numpy().astype(\"float32\"),5)\n",
    "\n",
    "                    # print(type(img_id), type(sigmoid_output), type(sigmoid_output.tolist()), type(list(sigmoid_output)))\n",
    "                    epoch_df.loc[len(epoch_df)] = [img_id] +  list(sigmoid_output)\n",
    "\n",
    "\n",
    "    return epoch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_epoch_runner_2(description:str, loader, model, device=\"cuda\"):\n",
    "    labels = [\"Class 1\",\"Class 2\",\"Class 3\",\"Class 4\",\"Class 5\",\"Class 6\"] # hidden class names\n",
    "    header = [\"ImageID\"] + [f\"CLASS {i}\" for i in range(1,5)] + [f\"PROB {i}\" for i in range(1,5)]\n",
    "    epoch_df = pd.DataFrame(columns=header)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(loader, desc=description.title()) as iterator:\n",
    "            for images, img_ids in iterator:\n",
    "\n",
    "                images = images.to(device)\n",
    "                outputs = model.forward(images)\n",
    "                sigmoid_outputs = torch.sigmoid(outputs)\n",
    "\n",
    "                for i in range(len(sigmoid_outputs)):\n",
    "\n",
    "                    top_4, top_4_indices = torch.topk(sigmoid_outputs[i], 4)\n",
    "                    img_id = img_ids[i]\n",
    "\n",
    "                    top_4 = list(np.round(top_4.cpu().numpy().astype(\"float32\"),5))\n",
    "                    top_4_indices = list(top_4_indices.cpu().numpy().astype(\"int8\"))\n",
    "\n",
    "                    epoch_df.loc[len(epoch_df)] = [img_id] +  [labels[i] for i in top_4_indices] + top_4\n",
    "\n",
    "\n",
    "                # predicted = (torch.sigmoid(outputs) >= 0.5).int()\n",
    "                # _, top_3 = torch.topk(torch.sigmoid(outputs), 3)\n",
    "                # top_3_labels.extend(top_3.cpu().numpy().astype(\"int8\"))\n",
    "                # predicted_labels.extend(predicted.cpu().numpy().astype(\"int8\"))\n",
    "\n",
    "    return epoch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = \"./Confidence-scores\"\n",
    "dirs = [\n",
    "    (\"./Results/Train Data\",\"CITY_1_2_Train\"),\n",
    "    (\"./Results/Test Images/CITY_1_2/Data_Classification\",\"CITY_1_2_Test\"),\n",
    "    (\"./Results/Test Images/CITY_3/Test_data_CITY_3_1\",\"CITY_3_1_Test\"),\n",
    "    (\"./Results/Test Images/CITY_3/Test_data_CITY_3_2\",\"CITY_3_2_Test\"),\n",
    "    (\"./Results/Test Images/CITY_3/Test_data_CITY_3_3\",\"CITY_3_3_Test\"),\n",
    "    (\"./Results/Test Images/CITY_3/Test_data_CITY_3_3a\",\"CITY_3_3a_Test\"),\n",
    "    (\"./Results/Test Images/CITY_4\",\"CITY_4_Test\"),\n",
    "]\n",
    "\n",
    "# Gives the confidence scores for each class\n",
    "for item in dirs:\n",
    "    inference_dataset = Dataset(\n",
    "    images_dir=item[0],\n",
    "    aug_fn=resize_image,\n",
    "    preprocessing=get_preprocessing()\n",
    "    )\n",
    "\n",
    "    inference_loader = DataLoader(inference_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    epoch_df = inference_epoch_runner_confidence_output(\"Inference\", inference_loader, model, device=DEVICE)\n",
    "    epoch_df.to_csv(f\"{dest_dir}/confidence_outputs/{item[1]}_confidence.csv\", index=False)\n",
    "\n",
    "# Gives the top 4 classes and their probabilities\n",
    "for item in dirs:\n",
    "    inference_dataset = Dataset(\n",
    "    images_dir=item[0],\n",
    "    aug_fn=resize_image,\n",
    "    preprocessing=get_preprocessing()\n",
    "    )\n",
    "\n",
    "    inference_loader = DataLoader(inference_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    epoch_df = inference_epoch_runner_2(\"Inference\", inference_loader, model, device=DEVICE)\n",
    "    epoch_df.to_csv(f\"{dest_dir}/top_4/{item[1]}_Top_4.csv\", index=False)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_iisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
