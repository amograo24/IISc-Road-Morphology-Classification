{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, efficientnet_b5, densenet161\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, roc_curve, RocCurveDisplay\n",
    "# sensitivity, specificity, precision, recall, f1_score, roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, hamming_loss, zero_one_loss\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "path_dir = \"./rpc/test_images/chandigarh\"\n",
    "model_path = \"./AUG-New-IISc/best_model/models/best_mopdel.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"./data-iisc\"\n",
    "images_dir = \"train_data_dir\"\n",
    "train_csv = \"train_data.csv\"\n",
    "val_csv = \"val_data.csv\"\n",
    "test_csv = \"test_data.csv\"\n",
    "class Dataset(BaseDataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            images_dir,\n",
    "            csv,\n",
    "            aug_fn=None,\n",
    "            preprocessing=None,\n",
    "            column_list = [\"Image_ID\", \"Class 1\",\"Class 2\",\"Class 3\",\"Class 4\",\"Class 5\",\"Class 6\"]\n",
    "    ):\n",
    "        images_dir = os.path.join(root,images_dir)\n",
    "        df = pd.read_csv(os.path.join(root,csv))\n",
    "\n",
    "        self.ids = [\n",
    "            (r[column_list[0]], r[column_list[1]], r[column_list[2]], r[column_list[3]], r[column_list[4]], r[column_list[5]], r[column_list[6]]) for i, r in df.iterrows()\n",
    "        ]\n",
    "\n",
    "        self.images = [os.path.join(images_dir, item[0]) for item in self.ids]\n",
    "        self.labels = [item[1:] for item in self.ids]\n",
    "\n",
    "        self.aug_fn = aug_fn\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.images[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[i]\n",
    "\n",
    "        if self.aug_fn:\n",
    "            sample = self.aug_fn(image.shape)(image=image)\n",
    "            image = sample['image']\n",
    "\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "            label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        return image, label, self.ids[i][0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image, pass it through albumentations, get the predicted labels, and then show the image\n",
    "def resize_image(image_shp, target_size=512):\n",
    "    \"\"\"\n",
    "    Resize the image to the target size\n",
    "    :param image: The image to resize\n",
    "    :param target_size: The target size\n",
    "    :return: The resized image\n",
    "    \"\"\"\n",
    "    h, w, _ = image_shp\n",
    "\n",
    "    max_size = max(h, w)\n",
    "\n",
    "    transform = A.Compose([\n",
    "    A.PadIfNeeded(min_height=max_size, min_width=max_size, border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255)),\n",
    "    A.Resize(512, 512, interpolation=cv2.INTER_AREA),\n",
    "    # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    return transform\n",
    "\n",
    "# %%\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype(\"float32\")\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn=None):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "\n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function\n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _transform = [\n",
    "        # Lambda(image=preprocessing_fn),\n",
    "        A.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet50(weights=None, num_classes=6)\n",
    "# model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "# model = densenet161(weights=None, num_classes=6)\n",
    "# model.features.conv0 = nn.Conv2d(1, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model = densenet161(weights='DEFAULT')\n",
    "model.classifier = torch.nn.Linear(2208, 6)\n",
    "\n",
    "# model = efficientnet_b5(weights=None)\n",
    "# model.classifier[1] = torch.nn.Linear(in_features=2048, out_features=6, bias=True)\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "checkpoint = torch.load(model_path,map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# model.load_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(\n",
    "    root=ROOT,\n",
    "    images_dir=images_dir,\n",
    "    csv=val_csv if not TEST else test_csv,\n",
    "    aug_fn=resize_image,\n",
    "    preprocessing=get_preprocessing()\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_runner(description:str, loader, model, loss, optimizer=None, device=\"cuda\"):\n",
    "    label_names = [\"Class 1\",\"Class 2\",\"Class 3\",\"Class 4\",\"Class 5\",\"Class 6\"]\n",
    "    epoch_loss = []\n",
    "    original_labels = []\n",
    "    predicted_labels = []\n",
    "    top_3_labels = []\n",
    "\n",
    "    running_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    val_count = 0\n",
    "\n",
    "    # train_mode = (description.lower() == \"train\")\n",
    "\n",
    "    run_modes = {\"train\":True,\"val\":False}\n",
    "    mode = run_modes[description.lower()]\n",
    "\n",
    "    # eps = 1e-10\n",
    "    # print(description.title())\n",
    "    # print(mode)\n",
    "\n",
    "    if mode:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    with torch.set_grad_enabled(mode):\n",
    "        with tqdm(loader, desc=description.title()) as iterator:\n",
    "            for images, labels, img_id in iterator:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                if mode:\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                outputs = model.forward(images)\n",
    "                # print(outputs.shape, labels.shape, labels.view(-1, 1).shape)   \n",
    "                loss_value = loss(outputs, labels)\n",
    "\n",
    "                if mode:\n",
    "                    loss_value.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, top_3 = torch.topk(torch.sigmoid(outputs), 3)\n",
    "                top_3_labels.extend(top_3.cpu().numpy().astype(\"int8\"))\n",
    "                predicted = (torch.sigmoid(outputs) >= 0.5).int()\n",
    "# '''\n",
    "                img_array = images[0].cpu().permute(1, 2, 0).numpy().squeeze()\n",
    "                img_array = img_array/np.max(img_array)\n",
    "\n",
    "                if torch.sigmoid(outputs)[0][5] >= torch.tensor(0.9):\n",
    "                # if True:\n",
    "                    # print(torch.sigmoid(outputs)[0][4])\n",
    "                    val_count += 1\n",
    "#######\n",
    "                #     plt.imshow(img_array)\n",
    "                #     plt.show()\n",
    "\n",
    "                # # #image_np = image_tensor.permute(1, 2, 0).numpy()\n",
    "\n",
    "                # # print(label_names)\n",
    "                #     print(\"Image ID: \", img_id)\n",
    "                #     print(\"Original Labels: \", labels)\n",
    "                #     print(\"Sigmoid Labels: \", torch.sigmoid(outputs))\n",
    "                # # print(\"SoftMax Labels: \", torch.softmax(outputs, dim=1))\n",
    "                # # print(\"Ordering Sigmoid: \",torch.argsort(torch.sigmoid(outputs), descending=True))\n",
    "                # # print(\"Ordering SoftMax: \",torch.argsort(torch.softmax(outputs, dim=1), descending=True))\n",
    "\n",
    "                #     print(\"Predicted Labels: \",predicted)\n",
    "                #########\n",
    "                    \n",
    "                # predicted = torch.zeros_like(outputs)\n",
    "                # # print(predicted.shape)\n",
    "                # for i in range(len(outputs)):\n",
    "                #     for j in range(len(outputs[i])):\n",
    "                #         if j == 0:\n",
    "                #             predicted[i][j] = (torch.sigmoid(outputs[i][j]) >= 0.08).int()\n",
    "                #         # elif j == 5:\n",
    "                #         #     predicted[i][j] = (torch.sigmoid(outputs[i][j]) >= 0.5).int()\n",
    "                #         else:\n",
    "                #             predicted[i][j] = (torch.sigmoid(outputs[i][j]) >= 0.5).int()\n",
    "                            \n",
    "\n",
    "                running_loss += loss_value.item()\n",
    "                count += 1\n",
    "                epoch_loss.append(loss_value.item())\n",
    "                original_labels.extend(labels.cpu().numpy().astype(\"int8\"))\n",
    "                predicted_labels.extend(predicted.cpu().numpy().astype(\"int8\"))\n",
    "                # print(predicted.cpu().numpy().astype(\"int8\"))\n",
    "\n",
    "                iterator.set_postfix({\"loss\":running_loss/count,\"Accuracy\":1-hamming_loss(original_labels, predicted_labels)})\n",
    "\n",
    "        epoch_loss_value = np.mean(epoch_loss)\n",
    "# labels=label_names\n",
    "        epoch_classification_report = classification_report(original_labels, predicted_labels)\n",
    "\n",
    "        print(\"Classification Report:\\n\", epoch_classification_report)\n",
    "        epoch_cr_dictionary = classification_report(original_labels, predicted_labels, output_dict=True)\n",
    "\n",
    "        epoch_mcm = multilabel_confusion_matrix(original_labels, predicted_labels)\n",
    "        epoch_auc = None\n",
    "        # epoch_auc = roc_auc_score(original_labels, predicted_labels,average=None)\n",
    "\n",
    "        epoch_hamming_loss = hamming_loss(original_labels, predicted_labels)\n",
    "        epoch_zero_one_loss = zero_one_loss(original_labels, predicted_labels)\n",
    "\n",
    "    # print(\"Original Labels: \", original_labels) \n",
    "    # print(\"Predicted Labels: \", predicted_labels)\n",
    "    print(\"Val Count: \", val_count)\n",
    "    return epoch_loss_value, epoch_cr_dictionary, epoch_mcm, epoch_auc, epoch_hamming_loss, epoch_zero_one_loss, top_3_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    val_loss, val_cr, val_mcm, val_auc, val_hamming_loss, val_zero_one_loss, top_3_labels = epoch_runner(\"val\", val_loader, model, nn.BCEWithLogitsLoss(), device=DEVICE)\n",
    "    # print(f\"Validation Loss: {val_loss}\")\n",
    "    # print(f\"Validation Hamming Loss: {val_hamming_loss}\")\n",
    "    # print(f\"Validation Zero One Loss: {val_zero_one_loss}\")\n",
    "    # print(f\"Validation AUC: {val_auc}\")\n",
    "    # print(f\"Validation Classification Report: {val_cr}\")\n",
    "    # print(f\"Validation MCM:\\n{val_mcm}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"top 3 labels: \", top_3_labels)\n",
    "labels = [\"Class 1\",\"Class 2\",\"Class 3\",\"Class 4\",\"Class 5\",\"Class 6\"]\n",
    "\n",
    "count = {}\n",
    "\n",
    "for i in range(len(top_3_labels)):\n",
    "    new_list = tuple([labels[j] for j in top_3_labels[i]])\n",
    "    count[new_list] = count.get(new_list, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in count.items():\n",
    "    print(key, value)\n",
    "\n",
    "print(len(count.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_iisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
